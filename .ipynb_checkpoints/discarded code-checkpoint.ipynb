{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist_id = \"UU4a-Gbdw7vOaccHmFo40b9g\" #This is the default playlist id for Khan Academy\n",
    "\n",
    "def get_youtube_playlist(playlist_id, max_results=50):\n",
    "    \n",
    "    youtube = build(serviceName = YOUTUBE_API_SERVICE_NAME,\n",
    "                    version = YOUTUBE_API_VERSION,\n",
    "                    developerKey = DEVELOPER_KEY)\n",
    "    \n",
    "    search_response = youtube.playlistItems().list(\n",
    "        playlistId = playlist_id,\n",
    "        part = 'snippet',\n",
    "        maxResults= max_results)\n",
    "    \n",
    "    return search_response.execute()\n",
    "\n",
    "playlist_result = get_youtube_playlist(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = []\n",
    "\n",
    "for item in playlist_result[\"items\"]:\n",
    "    A=item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
    "    print A\n",
    "    videos.append(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following API call retrieves the \"id\" part of the channel resource that contains information about Khan Academy's channel. This is the channel id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_channel_id(channel_name, max_results=50):\n",
    "    \n",
    "    youtube = build(serviceName = YOUTUBE_API_SERVICE_NAME,\n",
    "                    version = YOUTUBE_API_VERSION,\n",
    "                    developerKey = DEVELOPER_KEY)\n",
    "    \n",
    "    query_response = youtube.channels().list(\n",
    "        forUsername = channel_name,\n",
    "        part = 'id',\n",
    "        maxResults= max_results)\n",
    "    \n",
    "    return query_response.execute()\n",
    "\n",
    "result = get_channel_id(\"khanacademy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_video_ids = \",\".join(videos)\n",
    "test_video_ids = test_video_ids+\",\"+test_video_ids\n",
    "print test_video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take that list of 50 video ids and get a bunch of statistics for them using the Videos resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_statistics(video_ids, max_results=50):\n",
    "    \"\"\"returns a youtube API Video resource, containing details for a list of videos\"\"\"\n",
    "    \n",
    "    youtube = build(serviceName = YOUTUBE_API_SERVICE_NAME,\n",
    "                    version = YOUTUBE_API_VERSION,\n",
    "                    developerKey = DEVELOPER_KEY)\n",
    "    \n",
    "    search_response = youtube.videos().list(\n",
    "        id = video_ids,\n",
    "        part = 'snippet,statistics',\n",
    "        maxResults= max_results)\n",
    "    \n",
    "    return search_response.execute()\n",
    "\n",
    "video_result = get_video_statistics(test_video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now got some statistics for the 50 videos captured above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for item in video_result[\"items\"]:\n",
    "    A = float(item[\"statistics\"][\"viewCount\"])\n",
    "    B = float(item[\"statistics\"][\"likeCount\"])\n",
    "    C = float(B/A)\n",
    "    print int(A), int(B), C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should figure out how to use pagination of results. We'll choose the default playlist of 3Blue1Brown as our testing grounds. This channel currently has about 70 videos, so we should expect just 2 pages of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_channelId = \"UCYO_jab_esuFRV4b17AJtAw\"\n",
    "bb_playlist_id = \"UUYO_jab_esuFRV4b17AJtAw\"\n",
    "\n",
    "def get_next_page_token(response):\n",
    "    \"\"\"Given json Youtube API response, return next_page token\"\"\"\n",
    "    try:\n",
    "        return response[\"nextPageToken\"] \n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "def num_results(response):\n",
    "    \"Get number of results to query\"\n",
    "    return int(response[\"pageInfo\"][\"totalResults\"])\n",
    "\n",
    "\n",
    "def add_playlist_video_details(response, dataset):\n",
    "    \"\"\"reads a playlist call response and extracts dict of desired information\"\"\" \n",
    "    for item in response[\"items\"]:\n",
    "        video_id = item[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
    "        dataset[video_id] = {\"likes\":1, \"dislikes\":3, \"views\":20} #arbitrary\n",
    "    return dataset\n",
    "\n",
    "def add_search_video_details(response, dataset):\n",
    "    \"\"\"reads a search call response and extracts dict of desired information\"\"\" \n",
    "    for item in response[\"items\"]:\n",
    "        print item\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        dataset[video_id] = {\"likes\":1, \"dislikes\":3, \"views\":20} #arbitrary\n",
    "    return dataset\n",
    "\n",
    "def get_paginated_playlist(playlist_id, max_results=50, first_token=None):\n",
    "    \n",
    "    youtube = build(serviceName = YOUTUBE_API_SERVICE_NAME,\n",
    "                    version = YOUTUBE_API_VERSION,\n",
    "                    developerKey = DEVELOPER_KEY)\n",
    "    \n",
    "    token = None\n",
    "    \n",
    "    search_response = youtube.playlistItems().list(\n",
    "        playlistId = playlist_id,\n",
    "        part = 'snippet',\n",
    "        maxResults= max_results,\n",
    "        pageToken =None)\n",
    "    \n",
    "    result = search_response.execute()\n",
    "    \n",
    "    token =  get_next_page_token(result)\n",
    "    \n",
    "    search_response2 = youtube.playlistItems().list(\n",
    "        playlistId = playlist_id,\n",
    "        part = 'snippet',\n",
    "        maxResults= max_results,\n",
    "        pageToken = token\n",
    "        )\n",
    "    \n",
    "    return search_response2.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_results = get_youtube_playlist(bb_playlist_id)\n",
    "bb_results_2 = get_paginated_playlist(bb_playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_video_details_from_playlist(playlist_id):\n",
    "    \"\"\"Gets all videos on a youtube playlist by collecting paginated results\"\"\"\n",
    "    \n",
    "    youtube = build(serviceName = YOUTUBE_API_SERVICE_NAME,\n",
    "                    version = YOUTUBE_API_VERSION,\n",
    "                    developerKey = DEVELOPER_KEY)\n",
    "    dataset = {}\n",
    "    \n",
    "    query = youtube.playlistItems().list(\n",
    "                playlistId = playlist_id,\n",
    "                part = 'snippet',\n",
    "                pageToken=None)\n",
    "    first_page = query.execute()\n",
    "    \n",
    "    token = get_next_page_token(first_page)\n",
    "    dataset = add_playlist_video_details(first_page, dataset) \n",
    "    #maybe create a dataset class with some nice methods?\n",
    "    \n",
    "    while token:\n",
    "        \n",
    "        query = youtube.playlistItems().list(\n",
    "            playlistId = playlist_id,\n",
    "            part = 'snippet',\n",
    "            pageToken = token\n",
    "            )\n",
    "        page_response = query.execute()\n",
    "        \n",
    "        token = get_next_page_token(page_response)\n",
    "        dataset = add_playlist_video_details(page_response, dataset) \n",
    "    \n",
    "    return dataset\n",
    "\n",
    "bb_results_3 = get_video_details_from_playlist(bb_playlist_id)\n",
    "len(bb_results_3) #expected = 67ish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries using PlaylistItems have a hard cap of 500 items. We'll need to use the Search resource to get beyond this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_videos_from_channel_using_search(channel_id):\n",
    "    \"\"\"Gets all videos on a youtube channel by collecting paginated results\"\"\"\n",
    "    \n",
    "    youtube = build(serviceName = YOUTUBE_API_SERVICE_NAME,\n",
    "                    version = YOUTUBE_API_VERSION,\n",
    "                    developerKey = DEVELOPER_KEY)\n",
    "    dataset = {}\n",
    "    \n",
    "    query = youtube.search().list(\n",
    "                q=\"\",\n",
    "                part = 'snippet,id',\n",
    "                pageToken=None,\n",
    "                channelId = channel_id)\n",
    "    first_page = query.execute()\n",
    "    \n",
    "    token = get_next_page_token(first_page)\n",
    "    dataset = add_search_video_details(first_page, dataset) \n",
    "    #maybe create a dataset class with some nice methods?\n",
    "    \n",
    "    while token:\n",
    "        \n",
    "        query = youtube.search().list(\n",
    "            q=\"\",\n",
    "            part = 'snippet,id',\n",
    "            pageToken = token,\n",
    "            channelId = channel_id\n",
    "            )\n",
    "        page_response = query.execute()\n",
    "        \n",
    "        token = get_next_page_token(page_response)\n",
    "        dataset = add_search_video_details(page_response, dataset) \n",
    "    \n",
    "    return dataset\n",
    "\n",
    "h3h3_results = get_videos_from_channel_using_search(h3h3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we will need to increase efficiency by performing our surveys asynchronously, below is an example using trollius, the (now deprecated) python 2.7 port of the python 3.4+ native asynchronous programming module, asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import trollius as asyncio\n",
    "from trollius import From\n",
    "\n",
    "@asyncio.coroutine\n",
    "def factorial(name, number):\n",
    "    f = 1\n",
    "    for i in range(2, number + 1):\n",
    "        print(\"Task %s: Compute factorial(%d)...\" % (name, i))\n",
    "        yield From(asyncio.sleep(1))\n",
    "        f *= i\n",
    "    print(\"Task %s completed! factorial(%d) is %d\" % (name, number, f))\n",
    "\n",
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(loop)\n",
    "tasks = [\n",
    "    asyncio.async(factorial(\"A\", 8)),\n",
    "    asyncio.async(factorial(\"B\", 3)),\n",
    "    asyncio.async(factorial(\"C\", 4))]\n",
    "loop.run_until_complete(asyncio.wait(tasks))\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know how to use this in conjunction with the Youtube API, so I may have to either/both switch to python 3 or/and write my own POST requests to the API.\n",
    "\n",
    "Fortunately, there's another asynchronous programming package for python -  gevent. Below we add to a short example from http://sdiehl.github.io/gevent-tutorial/ which demonstrates the speed up from non-blocking code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gevent\n",
    "import random\n",
    "import time\n",
    "\n",
    "rands = [random.randint(0,2)*0.1 for i_ in range(10)]\n",
    "\n",
    "tic = lambda t: (time.time() - t)*1000 #time since t in ms \n",
    "\n",
    "def task(pid, wait_t):\n",
    "    \"\"\"\n",
    "    Some non-deterministic task\n",
    "    \"\"\"\n",
    "    task_start = time.time()\n",
    "    gevent.sleep(wait_t)\n",
    "    print 'Task {0} done at {1:1.2f} ms, took {2:1.2f} ms'.format(pid, tic(start),tic(task_start))\n",
    "\n",
    "def synchronous():\n",
    "    for pid, wait_t in enumerate(rands):\n",
    "        task(pid, wait_t)\n",
    "\n",
    "def asynchronous():\n",
    "    threads = [gevent.spawn(task, *(pid,wait_t)) for pid, wait_t in enumerate(rands)]\n",
    "    gevent.joinall(threads)\n",
    "\n",
    "start = time.time()  \n",
    "print 'Synchronous:'\n",
    "synchronous()\n",
    "print \"All done in {:2.1f} ms\".format(tic(start))\n",
    "\n",
    "start = time.time()\n",
    "print 'Asynchronous:'\n",
    "asynchronous()\n",
    "print \"All done in {:2.1f} ms\".format(tic(start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second set of tasks are clearly happening at the same time, but there's some extra processing time sneaking in somewhere. Note that the individual working time of each task is the same across async and sync, but that async does them all (nearly) at once, as desired!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gevent.monkey\n",
    "gevent.monkey.patch_socket()\n",
    "import time\n",
    "import gevent\n",
    "# import urllib2\n",
    "import requests\n",
    "# import simplejson as json\n",
    "\n",
    "tic = lambda t: (time.time() -t)*1000 # time since t in ms\n",
    "\n",
    "target_url = 'https://www.googleapis.com/youtube/v3/search?part=snippet&channelId=UCDWIvJwLJsE4LG1Atne2blQ&maxResults=50&type=video&key={0}'.format(DEVELOPER_KEY)\n",
    "# target_url = 'https://jsonplaceholder.typicode.com/posts/1'\n",
    "\n",
    "def fetch(pid):\n",
    "    start = time.time()\n",
    "    response = requests.get(target_url)\n",
    "    json_result = response.json()\n",
    "    print 'Process {}: {:.2f}'.format(pid, tic(start))\n",
    "    return json_result\n",
    "    return None\n",
    "\n",
    "def synchronous():\n",
    "    for i in range(1,5):\n",
    "        fetch(i)\n",
    "\n",
    "def asynchronous():\n",
    "    threads = []\n",
    "    for i in range(1,5):\n",
    "        threads.append(gevent.spawn(fetch, i))\n",
    "    return gevent.joinall(threads)\n",
    "\n",
    "p_start = time.time()\n",
    "print 'Synchronous:'\n",
    "synchronous()\n",
    "print \"All done in {:.2f}\".format(tic(p_start))\n",
    "\n",
    "p_start = time.time()\n",
    "print 'Asynchronous:'\n",
    "responses = asynchronous()\n",
    "print \"All done in {:.2f}\".format(tic(p_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requests are sort-of being sent asynchronously (since they are returned out of order), but it seems that requests is blocking IO somewhere. Any difference in total completion time between async and sync processes is just due to the random response time of the server.\n",
    "\n",
    "Fortunately, there is grequests for async requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
